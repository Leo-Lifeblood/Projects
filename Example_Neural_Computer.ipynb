{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcDueM/CivlcsjasgOTFXQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leo-Lifeblood/Projects/blob/main/Example_Neural_Computer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "vMpo17szV7fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node(nn.Module):\n",
        "    def __init__(self, output_size):\n",
        "      super(Node, self).__init__()\n",
        "      self.key = nn.Parameter(torch.randn(1, output_size))\n",
        "      self.norm = nn.LazyBatchNorm1d()\n",
        "      self.fc = nn.LazyLinear(output_size*4)\n",
        "      self.fc2 = nn.LazyLinear(output_size)\n",
        "      self.terminator = nn.LazyLinear(1)\n",
        "      self.terminator_activation = nn.Sigmoid()\n",
        "      self.activation = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      x2 = self.norm(x)\n",
        "      x2 = self.fc(x2)\n",
        "      x_int = self.activation(x2)\n",
        "      x2 = self.fc2(x_int)\n",
        "      x2 = self.activation(x2)\n",
        "      term = self.terminator(x_int)\n",
        "      term = self.terminator_activation(term)\n",
        "\n",
        "      return x+x2, term\n",
        "\n"
      ],
      "metadata": {
        "id": "5RxdcTS-WPTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node(nn.Module):\n",
        "    def __init__(self, output_size):\n",
        "      super(Node, self).__init__()\n",
        "      self.key = nn.Parameter(torch.randn(1, output_size))\n",
        "      self.norm = nn.LazyBatchNorm1d()\n",
        "      self.fc = nn.LazyLinear(output_size*4)\n",
        "      self.fc2 = nn.LazyLinear(output_size)\n",
        "      self.terminator = nn.LazyLinear(1)\n",
        "      self.terminator_activation = nn.Sigmoid()\n",
        "      self.activation = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      x2 = self.norm(x)\n",
        "      x2 = self.fc(x2)\n",
        "      x_int = self.activation(x2)\n",
        "      x2 = self.fc2(x_int)\n",
        "      x2 = self.activation(x2)\n",
        "      term = self.terminator(x_int)\n",
        "      term = self.terminator_activation(term)\n",
        "\n",
        "      return x+x2, term\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, num_options=6, hidden_dim=64):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.state = nn.LazyLinear(hidden_dim)\n",
        "        self.action = nn.LazyLinear(hidden_dim)\n",
        "        self.layer_reservoir = nn.ModuleList([Node(hidden_dim) for _ in range(num_options)])\n",
        "        self.num_options = num_options\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.extender1 = nn.LazyLinear(hidden_dim)\n",
        "        self.extender2 = nn.LazyLinear(hidden_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_state = self.state(x)\n",
        "        x_action = self.action(x)\n",
        "\n",
        "        terminator = torch.ones(x.shape[0],1)\n",
        "\n",
        "        heads = torch.concat([i.key for i in self.layer_reservoir], dim=0)\n",
        "\n",
        "        end = 0\n",
        "\n",
        "        step_count = 0\n",
        "\n",
        "        while (end <= 3) and (step_count < 15):\n",
        "          queries = x_action#F.normalize(x_action)\n",
        "\n",
        "          keys = heads.unsqueeze(0)\n",
        "\n",
        "\n",
        "          scores = torch.matmul(queries, keys.transpose(-1, -2)) / torch.sqrt(torch.tensor(self.num_options, dtype=torch.float32))\n",
        "          scores = torch.softmax(scores, dim=-1).squeeze(1).transpose(0, 1)\n",
        "\n",
        "          predictions = [i(x_state) for i in self.layer_reservoir]\n",
        "\n",
        "          terminators = torch.stack([i[1] for i in predictions], dim=1)\n",
        "          predictions = torch.stack([i[0] for i in predictions], dim=1)\n",
        "\n",
        "\n",
        "          prediction = torch.sum(predictions * scores.transpose(-2,-1), dim=1)\n",
        "\n",
        "          term = (terminators * scores.transpose(-2,-1)).squeeze().sum(dim=-1, keepdim=True)\n",
        "\n",
        "          terminator *= term\n",
        "\n",
        "          x_state = x_state + self.extender1(prediction)\n",
        "          x_action = x_action + self.extender2(prediction)\n",
        "\n",
        "          step_count += 1\n",
        "\n",
        "          if terminator.mean() > 0.1:\n",
        "            end +=1\n",
        "\n",
        "        return x_state\n",
        "\n",
        "    def logging_forward(self, x):\n",
        "        x_state = self.state(x)\n",
        "        x_action = self.action(x)\n",
        "\n",
        "        terminator = torch.ones(x.shape[0],1)\n",
        "\n",
        "        heads = torch.concat([i.key for i in self.layer_reservoir], dim=0)\n",
        "\n",
        "        end = 0\n",
        "\n",
        "        step_count = 0\n",
        "\n",
        "        while (end <= 3) and (step_count < 15):\n",
        "          queries = x_action#F.normalize(x_action)\n",
        "\n",
        "          keys = heads.unsqueeze(0)\n",
        "\n",
        "\n",
        "          scores = torch.matmul(queries, keys.transpose(-1, -2)) / torch.sqrt(torch.tensor(self.num_options, dtype=torch.float32))\n",
        "          scores = torch.softmax(scores, dim=-1).squeeze(1).transpose(0, 1)\n",
        "\n",
        "          print(scores)\n",
        "\n",
        "          predictions = [i(x_state) for i in self.layer_reservoir]\n",
        "\n",
        "          terminators = torch.stack([i[1] for i in predictions], dim=1)\n",
        "          predictions = torch.stack([i[0] for i in predictions], dim=1)\n",
        "\n",
        "\n",
        "          prediction = torch.sum(predictions * scores.transpose(-2,-1), dim=1)\n",
        "\n",
        "          term = (terminators * scores.transpose(-2,-1)).squeeze().sum(dim=-1, keepdim=True)\n",
        "\n",
        "          terminator *= term\n",
        "\n",
        "          x_state = x_state + self.extender1(prediction)\n",
        "          x_action = x_action + self.extender2(prediction)\n",
        "\n",
        "          step_count += 1\n",
        "\n",
        "          if terminator.mean() > 0.1:\n",
        "            end +=1\n",
        "\n",
        "        return x_state\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HQMBt2rfWBHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.autograd.set_detect_anomaly(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8LMg7HriEkF",
        "outputId": "bb424ddf-1620-49fb-9c14-cb530472bc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7db4a3ca4e50>"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = NeuralNetwork()"
      ],
      "metadata": {
        "id": "01xE3S_zZLW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(example.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Y6tF50F2hmgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_data = torch.randn(2, 64)"
      ],
      "metadata": {
        "id": "PVVpbY0Fjmrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example.eval()\n",
        "example.logging_forward(example_data)\n",
        "example.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jREKUdICjehJ",
        "outputId": "24607881-d612-40d3-c9f7-e7c17eed06b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0031, 0.0046, 0.5644, 0.0080, 0.3446, 0.0753]],\n",
            "\n",
            "        [[0.0501, 0.5371, 0.2608, 0.0573, 0.0613, 0.0332]]],\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "tensor([[[0.0048, 0.0156, 0.3785, 0.0404, 0.4549, 0.1058]],\n",
            "\n",
            "        [[0.2106, 0.6071, 0.0364, 0.0682, 0.0724, 0.0053]]],\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "tensor([[[0.0046, 0.0795, 0.1308, 0.4704, 0.2859, 0.0289]],\n",
            "\n",
            "        [[0.5558, 0.3604, 0.0049, 0.0435, 0.0342, 0.0012]]],\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "tensor([[[1.7476e-04, 3.5297e-02, 1.9736e-03, 9.5894e-01, 3.5257e-03,\n",
            "          9.0016e-05]],\n",
            "\n",
            "        [[9.0791e-01, 7.2898e-02, 4.7926e-04, 1.1984e-02, 6.4962e-03,\n",
            "          2.3455e-04]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[4.0653e-07, 3.2399e-03, 4.1318e-06, 9.9675e-01, 8.9683e-07,\n",
            "          4.1396e-09]],\n",
            "\n",
            "        [[9.9350e-01, 4.3677e-03, 3.2237e-05, 1.4163e-03, 6.6211e-04,\n",
            "          2.6612e-05]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[2.2851e-11, 1.4482e-04, 3.7385e-09, 9.9986e-01, 3.3350e-12,\n",
            "          2.9004e-15]],\n",
            "\n",
            "        [[9.9968e-01, 1.1570e-04, 2.3733e-06, 1.2403e-04, 7.9415e-05,\n",
            "          1.6446e-06]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[5.3129e-18, 7.1885e-06, 5.3012e-12, 9.9999e-01, 3.3742e-20,\n",
            "          1.5106e-23]],\n",
            "\n",
            "        [[9.9995e-01, 2.4894e-06, 4.1585e-07, 1.7666e-05, 2.6130e-05,\n",
            "          6.6099e-08]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[6.3026e-28, 1.4214e-06, 1.1254e-13, 1.0000e+00, 1.1803e-31,\n",
            "          2.9661e-34]],\n",
            "\n",
            "        [[9.9989e-01, 1.5529e-07, 9.1522e-07, 2.1636e-05, 8.2519e-05,\n",
            "          4.7336e-09]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[4.8205e-42, 4.9801e-06, 1.2061e-12, 9.9999e-01, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[9.6743e-01, 3.6980e-07, 6.0728e-04, 6.3052e-03, 2.5659e-02,\n",
            "          8.0872e-09]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[0.0000e+00, 7.6607e-04, 1.5992e-06, 9.9923e-01, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[2.1526e-06, 1.3602e-08, 8.9544e-02, 5.7470e-01, 3.3575e-01,\n",
            "          1.9375e-10]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[0.0000e+00, 3.7639e-09, 1.0000e+00, 3.9429e-10, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[2.5728e-25, 3.0785e-15, 1.1795e-04, 9.6277e-01, 3.7114e-02,\n",
            "          8.5963e-17]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[0.0000e+00, 5.0032e-25, 1.0000e+00, 7.8227e-39, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[0.0000e+00, 4.0899e-27, 3.6536e-12, 1.0000e+00, 5.7978e-07,\n",
            "          6.1318e-29]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[0.0000e+00, 0.0000e+00, 1.1758e-23, 1.0000e+00, 4.4838e-18,\n",
            "          0.0000e+00]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[0.0000e+00, 0.0000e+00, 7.7953e-40, 1.0000e+00, 1.6002e-36,\n",
            "          0.0000e+00]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[0., 0., 1., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 1., 0., 0.]]], grad_fn=<TransposeBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (state): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (action): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (layer_reservoir): ModuleList(\n",
              "    (0-5): 6 x Node(\n",
              "      (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (fc): Linear(in_features=64, out_features=256, bias=True)\n",
              "      (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "      (terminator): Linear(in_features=256, out_features=1, bias=True)\n",
              "      (terminator_activation): Sigmoid()\n",
              "      (activation): SiLU()\n",
              "    )\n",
              "  )\n",
              "  (extender1): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (extender2): Linear(in_features=64, out_features=64, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_examples = 2048\n",
        "batch_size = 256\n",
        "\n",
        "example_x = torch.randn(num_examples, 64)\n",
        "example_y = torch.randn(num_examples, 64)\n",
        "\n",
        "for epoch in range(10):\n",
        "  for batch in range(0, num_examples, batch_size):\n",
        "    batch_x = example_x[batch:batch+batch_size]\n",
        "    batch_y = example_y[batch:batch+batch_size]\n",
        "    optimizer.zero_grad()\n",
        "    output = example(batch_x)\n",
        "    loss = F.mse_loss(output, batch_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqoQKwCLZOQc",
        "outputId": "bb9480d9-c3eb-47a2-ce58-28767076537a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111.86737823486328\n",
            "109.95809936523438\n",
            "110.28087615966797\n",
            "108.80140686035156\n",
            "112.84201049804688\n",
            "103.87139892578125\n",
            "108.24845886230469\n",
            "107.38261413574219\n",
            "100.46147155761719\n",
            "98.75789642333984\n",
            "99.04219818115234\n",
            "98.05561065673828\n",
            "101.63528442382812\n",
            "93.55934143066406\n",
            "97.55122375488281\n",
            "96.94429779052734\n",
            "90.48837280273438\n",
            "89.01153564453125\n",
            "89.25438690185547\n",
            "88.72948455810547\n",
            "91.90441131591797\n",
            "84.5938491821289\n",
            "88.26659393310547\n",
            "87.88243865966797\n",
            "81.86488342285156\n",
            "80.5920181274414\n",
            "80.76351928710938\n",
            "80.64463806152344\n",
            "83.4783706665039\n",
            "76.81646728515625\n",
            "80.2093505859375\n",
            "80.04308319091797\n",
            "74.39612579345703\n",
            "73.30374908447266\n",
            "73.3805160522461\n",
            "73.6016616821289\n",
            "76.15754699707031\n",
            "70.02249145507812\n",
            "73.16389465332031\n",
            "73.23617553710938\n",
            "67.90100860595703\n",
            "66.95006561279297\n",
            "66.9102554321289\n",
            "67.4134521484375\n",
            "69.7148208618164\n",
            "64.03864288330078\n",
            "66.95362854003906\n",
            "67.2740249633789\n",
            "62.18050765991211\n",
            "61.365596771240234\n",
            "61.17934036254883\n",
            "61.921512603759766\n",
            "64.00006103515625\n",
            "58.7158203125\n",
            "61.44645309448242\n",
            "61.99146270751953\n",
            "57.09099578857422\n",
            "56.38697814941406\n",
            "56.10171127319336\n",
            "56.990196228027344\n",
            "58.913665771484375\n",
            "53.95452880859375\n",
            "56.554588317871094\n",
            "57.24469757080078\n",
            "52.52909469604492\n",
            "51.90064239501953\n",
            "51.58134460449219\n",
            "52.484493255615234\n",
            "54.36579132080078\n",
            "49.66173553466797\n",
            "52.14433670043945\n",
            "52.95392608642578\n",
            "48.450111389160156\n",
            "47.80883026123047\n",
            "47.548484802246094\n",
            "48.41349792480469\n",
            "50.26357650756836\n",
            "45.759620666503906\n",
            "48.12721633911133\n",
            "49.05864334106445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example.eval()\n",
        "example.logging_forward(example_data)\n",
        "example.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaQtDU91lw6q",
        "outputId": "256755cb-45ed-414e-f4b9-d507b0dbd896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[8.1711e-04, 3.5442e-03, 9.2644e-01, 7.8048e-03, 3.7411e-02,\n",
            "          2.3983e-02]],\n",
            "\n",
            "        [[8.2024e-03, 4.8116e-01, 4.2774e-01, 4.0761e-02, 2.3652e-02,\n",
            "          1.8481e-02]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[8.0713e-04, 2.6317e-02, 9.0784e-01, 4.2102e-02, 9.5266e-03,\n",
            "          1.3407e-02]],\n",
            "\n",
            "        [[1.4378e-02, 8.4126e-01, 9.4974e-02, 3.5612e-02, 1.1143e-02,\n",
            "          2.6330e-03]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[2.5253e-04, 2.1797e-01, 4.9586e-01, 2.8407e-01, 6.7387e-04,\n",
            "          1.1764e-03]],\n",
            "\n",
            "        [[1.6084e-02, 9.3073e-01, 3.3705e-02, 1.6895e-02, 1.9873e-03,\n",
            "          6.0294e-04]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[8.2765e-06, 3.7612e-01, 5.4226e-02, 5.6963e-01, 3.1949e-06,\n",
            "          5.2411e-06]],\n",
            "\n",
            "        [[2.0846e-02, 9.3585e-01, 3.4825e-02, 7.7912e-03, 3.3936e-04,\n",
            "          3.5005e-04]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[7.8269e-08, 2.2780e-01, 3.6182e-03, 7.6859e-01, 1.6927e-09,\n",
            "          2.6556e-09]],\n",
            "\n",
            "        [[3.8427e-02, 8.4652e-01, 1.1012e-01, 4.2564e-03, 1.1595e-04,\n",
            "          5.5503e-04]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[3.2127e-10, 5.4757e-02, 2.6464e-04, 9.4498e-01, 8.3177e-14,\n",
            "          1.8711e-13]],\n",
            "\n",
            "        [[6.5584e-02, 4.1098e-01, 5.2032e-01, 1.7542e-03, 9.5539e-05,\n",
            "          1.2653e-03]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[5.4795e-13, 5.3123e-03, 2.8579e-05, 9.9466e-01, 2.2859e-19,\n",
            "          1.8162e-18]],\n",
            "\n",
            "        [[3.8850e-02, 4.4131e-02, 9.1569e-01, 2.0092e-04, 1.0430e-04,\n",
            "          1.0271e-03]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[4.1626e-16, 2.9601e-04, 7.5544e-06, 9.9970e-01, 3.1427e-26,\n",
            "          3.3984e-24]],\n",
            "\n",
            "        [[1.8330e-02, 3.2216e-03, 9.7752e-01, 1.3323e-05, 4.3293e-04,\n",
            "          4.8513e-04]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[1.3267e-19, 1.2706e-05, 6.4355e-06, 9.9998e-01, 2.7337e-34,\n",
            "          1.7555e-30]],\n",
            "\n",
            "        [[1.2936e-02, 4.6918e-04, 9.7337e-01, 8.2164e-07, 1.3027e-02,\n",
            "          2.0038e-04]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[1.4999e-23, 4.4519e-07, 1.4442e-05, 9.9999e-01, 3.2370e-43,\n",
            "          3.2823e-37]],\n",
            "\n",
            "        [[5.3085e-03, 8.4258e-05, 3.2889e-01, 1.8500e-08, 6.6570e-01,\n",
            "          2.1022e-05]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[4.9620e-28, 9.1929e-09, 3.2555e-05, 9.9997e-01, 0.0000e+00,\n",
            "          2.2421e-44]],\n",
            "\n",
            "        [[4.9510e-05, 1.4086e-06, 2.8651e-03, 1.2416e-11, 9.9708e-01,\n",
            "          2.0866e-08]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[4.3996e-33, 5.1309e-11, 1.0087e-05, 9.9999e-01, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[7.6054e-07, 1.4559e-07, 7.5863e-05, 3.7582e-14, 9.9992e-01,\n",
            "          1.2306e-11]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[1.3386e-38, 2.4900e-14, 1.9830e-08, 1.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[5.6169e-08, 1.1440e-07, 3.3656e-05, 6.3645e-15, 9.9997e-01,\n",
            "          1.1903e-14]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[3.5032e-44, 3.2029e-19, 5.2575e-15, 1.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[2.1726e-08, 1.6566e-07, 6.1745e-04, 7.2022e-13, 9.9938e-01,\n",
            "          1.9686e-17]]], grad_fn=<TransposeBackward0>)\n",
            "tensor([[[0.0000e+00, 4.7919e-26, 3.7173e-27, 1.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00]],\n",
            "\n",
            "        [[2.2017e-08, 2.3033e-08, 3.5580e-01, 4.6353e-07, 6.4420e-01,\n",
            "          1.7644e-20]]], grad_fn=<TransposeBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (state): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (action): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (layer_reservoir): ModuleList(\n",
              "    (0-5): 6 x Node(\n",
              "      (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (fc): Linear(in_features=64, out_features=256, bias=True)\n",
              "      (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "      (terminator): Linear(in_features=256, out_features=1, bias=True)\n",
              "      (terminator_activation): Sigmoid()\n",
              "      (activation): SiLU()\n",
              "    )\n",
              "  )\n",
              "  (extender1): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (extender2): Linear(in_features=64, out_features=64, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    }
  ]
}